"""
Load canonical food catalog and alias map into PostgreSQL.

Prerequisites:
  - PostgreSQL schema created with:
      foods_canonical, food_aliases, food_nutrients
    (see DDL you defined earlier).
  - Files generated by normalize_food_catalog.py:
      - DANH-MUC-THUC-PHAM-CANONICAL.csv
      - food_alias_map.json

Usage:
  # Set connection string, ví dụ:
  #   export PG_DSN='postgresql://user:pass@localhost:5432/nutrition'
  # hoặc truyền qua --dsn
  python scripts/load_canonical_to_postgres.py \
    --dsn postgresql://user:pass@localhost:5432/nutrition \
    --canonical DANH-MUC-THUC-PHAM-CANONICAL.csv \
    --alias-map food_alias_map.json

Lưu ý:
  - Script chỉ insert/update (upsert) foods_canonical và food_aliases.
  - Bảng food_nutrients sẽ được điền dần sau, từ nguồn dinh dưỡng tin cậy.
"""

from __future__ import annotations

import argparse
import csv
import json
import os
from pathlib import Path
from typing import Dict, Iterable, List, Tuple

import psycopg2
from psycopg2.extras import execute_batch


def get_dsn(cli_dsn: str | None) -> str:
    if cli_dsn:
        return cli_dsn
    env = os.getenv("PG_DSN")
    if env:
        return env
    raise SystemExit(
        "Please provide PostgreSQL DSN via --dsn or PG_DSN environment variable "
        "(e.g. postgresql://user:pass@localhost:5432/nutrition)"
    )


def read_canonical_rows(path: Path) -> List[Dict[str, str]]:
    with path.open("r", encoding="utf-8", newline="") as f:
        reader = csv.DictReader(f)
        rows = [dict(r) for r in reader]
    return rows


def read_alias_map(path: Path) -> Dict[str, str]:
    data = json.loads(path.read_text(encoding="utf-8"))
    if not isinstance(data, dict):
        raise ValueError("alias_map JSON must be an object {alias_id: canonical_id}")
    # Normalize to str: str
    return {str(k): str(v) for k, v in data.items()}


def upsert_foods_canonical(cur, rows: Iterable[Dict[str, str]]) -> int:
    """
    Upsert into foods_canonical using canonical_id as PK.
    """
    sql = """
    INSERT INTO foods_canonical (
      canonical_id,
      code,
      name,
      display_name,
      accentless_name,
      short_name,
      slug,
      category,
      food_group,
      food_group_locked,
      alias,
      gi,
      gl,
      purine_level,
      fodmap_level,
      clinical_notes
    )
    VALUES (
      %(CanonicalId)s,
      NULLIF(%(Code)s, ''),
      %(Name)s,
      %(DisplayName)s,
      %(AccentlessName)s,
      NULLIF(%(ShortName)s, ''),
      %(Slug)s,
      NULLIF(%(Category)s, ''),
      %(FoodGroup)s::food_group_enum,
      COALESCE(NULLIF(%(FoodGroupLocked)s, ''), 'true')::boolean,
      NULLIF(%(Alias)s, ''),
      NULLIF(%(GI)s, '')::numeric,
      NULLIF(%(GL)s, '')::numeric,
      NULLIF(%(PurineLevel)s, '')::level_enum,
      NULLIF(%(FODMAPLevel)s, '')::level_enum,
      NULLIF(%(ClinicalNotes)s, '')
    )
    ON CONFLICT (canonical_id) DO UPDATE SET
      code              = EXCLUDED.code,
      name              = EXCLUDED.name,
      display_name      = EXCLUDED.display_name,
      accentless_name   = EXCLUDED.accentless_name,
      short_name        = EXCLUDED.short_name,
      slug              = EXCLUDED.slug,
      category          = EXCLUDED.category,
      food_group        = EXCLUDED.food_group,
      food_group_locked = EXCLUDED.food_group_locked,
      alias             = EXCLUDED.alias,
      gi                = EXCLUDED.gi,
      gl                = EXCLUDED.gl,
      purine_level      = EXCLUDED.purine_level,
      fodmap_level      = EXCLUDED.fodmap_level,
      clinical_notes    = EXCLUDED.clinical_notes;
    """

    batch = list(rows)
    if not batch:
        return 0
    execute_batch(cur, sql, batch, page_size=500)
    return len(batch)


def upsert_food_aliases(cur, alias_map: Dict[str, str], canonical_rows: List[Dict[str, str]]) -> int:
    """
    Upsert into food_aliases from alias_map + canonical CSV.
    - For alias rows: alias_id from JSON, canonical_id from value.
    - For canonical rows: we can optionally insert self-alias for debugging (here: we skip).
    """
    sql = """
    INSERT INTO food_aliases (alias_id, canonical_id, alias_name)
    VALUES (%(alias_id)s, %(canonical_id)s, %(alias_name)s)
    ON CONFLICT (alias_id) DO UPDATE SET
      canonical_id = EXCLUDED.canonical_id,
      alias_name   = COALESCE(EXCLUDED.alias_name, food_aliases.alias_name);
    """

    name_by_id = {row["Id"]: row.get("Name", "") for row in canonical_rows}
    batch: List[Dict[str, str]] = []
    for alias_id, canon_id in alias_map.items():
        alias_name = name_by_id.get(alias_id, "")
        batch.append(
            {
                "alias_id": alias_id,
                "canonical_id": canon_id,
                "alias_name": alias_name,
            }
        )

    if not batch:
        return 0

    execute_batch(cur, sql, batch, page_size=500)
    return len(batch)


def main() -> int:
    parser = argparse.ArgumentParser(description="Load canonical foods + alias map into PostgreSQL")
    parser.add_argument("--dsn", help="PostgreSQL DSN, e.g. postgresql://user:pass@host:5432/db")
    parser.add_argument(
        "--canonical",
        default="DANH-MUC-THUC-PHAM-CANONICAL.csv",
        help="Canonical CSV path",
    )
    parser.add_argument(
        "--alias-map",
        default="food_alias_map.json",
        help="Alias map JSON path",
    )
    args = parser.parse_args()

    dsn = get_dsn(args.dsn)
    canonical_path = Path(args.canonical)
    alias_path = Path(args.alias_map)

    canonical_rows = read_canonical_rows(canonical_path)
    alias_map = read_alias_map(alias_path)

    conn = psycopg2.connect(dsn)
    try:
        with conn:
            with conn.cursor() as cur:
                n_can = upsert_foods_canonical(cur, canonical_rows)
                n_alias = upsert_food_aliases(cur, alias_map, canonical_rows)
        print(f"Upserted {n_can} rows into foods_canonical")
        print(f"Upserted {n_alias} rows into food_aliases")
    finally:
        conn.close()

    return 0


if __name__ == "__main__":
    raise SystemExit(main())

